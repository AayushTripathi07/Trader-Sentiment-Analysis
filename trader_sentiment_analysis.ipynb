{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQxQ5thLHSNZ",
        "outputId": "49ade946-f8f9-4d1b-fc0e-ec9fd6074ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading datasets...\n",
            "Sentiment Shape: (2644, 4)\n",
            "Trader Shape: (211224, 16)\n",
            "\n",
            "Cleaning data...\n",
            "\n",
            "Missing Values Sentiment:\n",
            "timestamp         0\n",
            "value             0\n",
            "classification    0\n",
            "date              0\n",
            "dtype: int64\n",
            "\n",
            "Missing Values Trader:\n",
            "Account             0\n",
            "Coin                0\n",
            "Execution Price     0\n",
            "Size Tokens         0\n",
            "Size USD            0\n",
            "Side                0\n",
            "Timestamp IST       0\n",
            "Start Position      0\n",
            "Direction           0\n",
            "Closed PnL          0\n",
            "Transaction Hash    0\n",
            "Order ID            0\n",
            "Crossed             0\n",
            "Fee                 0\n",
            "Trade ID            0\n",
            "Timestamp           0\n",
            "dtype: int64\n",
            "\n",
            "Converting timestamps...\n",
            "\n",
            "Creating metrics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-572852022.py:124: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  win_rate = trader.groupby('account').apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating sentiment summary...\n",
            "\n",
            "Segmenting traders...\n",
            "\n",
            "Creating model features...\n",
            "\n",
            "Training predictive model...\n",
            "Model Accuracy: 0.7516930022573364\n",
            "\n",
            "Generating charts...\n",
            "\n",
            "===================================\n",
            "ANALYSIS COMPLETE\n",
            "===================================\n",
            "Final Accuracy: 0.7517\n",
            "All files saved in output folder\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Trader Performance vs Market Sentiment Analysis\n",
        "Primetrade.ai Assignment – Final Professional Version\n",
        "\n",
        "Author: Aayush Tripathi\n",
        "\n",
        "This script performs:\n",
        "• Data cleaning\n",
        "• Feature engineering\n",
        "• Sentiment analysis\n",
        "• Trader segmentation\n",
        "• Predictive modeling (no leakage)\n",
        "• Chart generation\n",
        "• Output generation\n",
        "\"\"\"\n",
        "\n",
        "# =============================\n",
        "# 1. IMPORT LIBRARIES\n",
        "# =============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 2. CREATE OUTPUT FOLDERS\n",
        "# =============================\n",
        "\n",
        "OUTPUT_FOLDER = \"output\"\n",
        "CHART_FOLDER = os.path.join(OUTPUT_FOLDER, \"charts\")\n",
        "\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "os.makedirs(CHART_FOLDER, exist_ok=True)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 3. LOAD DATA\n",
        "# =============================\n",
        "\n",
        "print(\"\\nLoading datasets...\")\n",
        "\n",
        "sentiment = pd.read_csv(\"fear_greed_index.csv\")\n",
        "trader = pd.read_csv(\"historical_data.csv\")\n",
        "\n",
        "print(\"Sentiment Shape:\", sentiment.shape)\n",
        "print(\"Trader Shape:\", trader.shape)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 4. CLEAN DATA\n",
        "# =============================\n",
        "\n",
        "print(\"\\nCleaning data...\")\n",
        "\n",
        "sentiment.drop_duplicates(inplace=True)\n",
        "trader.drop_duplicates(inplace=True)\n",
        "\n",
        "print(\"\\nMissing Values Sentiment:\")\n",
        "print(sentiment.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing Values Trader:\")\n",
        "print(trader.isnull().sum())\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 5. FIX TIMESTAMPS\n",
        "# =============================\n",
        "\n",
        "print(\"\\nConverting timestamps...\")\n",
        "\n",
        "sentiment['date'] = pd.to_datetime(\n",
        "    sentiment['date'],\n",
        "    errors='coerce'\n",
        ").dt.date\n",
        "\n",
        "\n",
        "trader['Timestamp IST'] = pd.to_datetime(\n",
        "    trader['Timestamp IST'],\n",
        "    dayfirst=True,\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "trader.dropna(subset=['Timestamp IST'], inplace=True)\n",
        "\n",
        "trader['date'] = trader['Timestamp IST'].dt.date\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 6. RENAME COLUMNS\n",
        "# =============================\n",
        "\n",
        "trader.rename(columns={\n",
        "\n",
        "    'Account': 'account',\n",
        "    'Coin': 'coin',\n",
        "    'Execution Price': 'execution_price',\n",
        "    'Size USD': 'size_usd',\n",
        "    'Closed PnL': 'closedPnL',\n",
        "    'Fee': 'fee'\n",
        "\n",
        "}, inplace=True)\n",
        "\n",
        "sentiment.rename(columns={\n",
        "    'classification': 'sentiment'\n",
        "}, inplace=True)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 7. CREATE BASIC METRICS\n",
        "# =============================\n",
        "\n",
        "print(\"\\nCreating metrics...\")\n",
        "\n",
        "daily_pnl = trader.groupby(['account','date'])['closedPnL'].sum().reset_index()\n",
        "\n",
        "win_rate = trader.groupby('account').apply(\n",
        "    lambda x: (x['closedPnL'] > 0).mean()\n",
        ").reset_index(name='win_rate')\n",
        "\n",
        "trade_frequency = trader.groupby(['account','date']).size().reset_index(name='num_trades')\n",
        "\n",
        "\n",
        "# Save metrics\n",
        "daily_pnl.to_csv(\"output/daily_pnl.csv\", index=False)\n",
        "win_rate.to_csv(\"output/win_rate.csv\", index=False)\n",
        "trade_frequency.to_csv(\"output/trade_frequency.csv\", index=False)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 8. MERGE SENTIMENT\n",
        "# =============================\n",
        "\n",
        "merged_analysis = pd.merge(\n",
        "    trader,\n",
        "    sentiment[['date','sentiment']],\n",
        "    on='date',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 9. SENTIMENT SUMMARY\n",
        "# =============================\n",
        "\n",
        "print(\"\\nCreating sentiment summary...\")\n",
        "\n",
        "sentiment_summary = merged_analysis.groupby('sentiment').agg({\n",
        "\n",
        "    'closedPnL': ['mean','median','std'],\n",
        "    'size_usd': 'mean',\n",
        "    'account': 'count'\n",
        "\n",
        "})\n",
        "\n",
        "sentiment_summary.columns = [\n",
        "\n",
        "    'avg_pnl',\n",
        "    'median_pnl',\n",
        "    'pnl_std',\n",
        "    'avg_trade_size',\n",
        "    'num_trades'\n",
        "\n",
        "]\n",
        "\n",
        "sentiment_summary.reset_index(inplace=True)\n",
        "\n",
        "sentiment_summary.to_csv(\"output/sentiment_summary.csv\", index=False)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 10. TRADER SEGMENTATION\n",
        "# =============================\n",
        "\n",
        "print(\"\\nSegmenting traders...\")\n",
        "\n",
        "segments = trader.groupby('account').agg({\n",
        "\n",
        "    'closedPnL': 'sum',\n",
        "    'coin': 'count',\n",
        "    'size_usd': 'mean'\n",
        "\n",
        "}).reset_index()\n",
        "\n",
        "segments.columns = [\n",
        "\n",
        "    'account',\n",
        "    'total_pnl',\n",
        "    'total_trades',\n",
        "    'avg_trade_size'\n",
        "\n",
        "]\n",
        "\n",
        "segments['segment'] = segments['total_pnl'].apply(\n",
        "    lambda x: \"Winner\" if x > 0 else \"Loser\"\n",
        ")\n",
        "\n",
        "segments.to_csv(\"output/trader_segments.csv\", index=False)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 11. CREATE FEATURES FOR MODEL\n",
        "# =============================\n",
        "\n",
        "print(\"\\nCreating model features...\")\n",
        "\n",
        "features = trader.groupby(['account','date']).agg({\n",
        "\n",
        "    'closedPnL': 'sum',\n",
        "    'size_usd': 'mean',\n",
        "    'fee': 'sum',\n",
        "    'coin': 'count'\n",
        "\n",
        "}).reset_index()\n",
        "\n",
        "features.rename(columns={\n",
        "\n",
        "    'closedPnL': 'daily_pnl',\n",
        "    'size_usd': 'avg_trade_size',\n",
        "    'fee': 'total_fee',\n",
        "    'coin': 'num_trades'\n",
        "\n",
        "}, inplace=True)\n",
        "\n",
        "\n",
        "# Add historical features\n",
        "features = features.sort_values(['account','date'])\n",
        "\n",
        "features['prev_day_pnl'] = features.groupby('account')['daily_pnl'].shift(1)\n",
        "\n",
        "features['rolling_3day_pnl'] = (\n",
        "    features.groupby('account')['daily_pnl']\n",
        "    .rolling(3)\n",
        "    .mean()\n",
        "    .reset_index(0,drop=True)\n",
        ")\n",
        "\n",
        "features['volatility'] = (\n",
        "    features.groupby('account')['daily_pnl']\n",
        "    .rolling(5)\n",
        "    .std()\n",
        "    .reset_index(0,drop=True)\n",
        ")\n",
        "\n",
        "\n",
        "# Merge sentiment\n",
        "features = pd.merge(\n",
        "    features,\n",
        "    sentiment[['date','sentiment']],\n",
        "    on='date'\n",
        ")\n",
        "\n",
        "features = pd.get_dummies(features, columns=['sentiment'], drop_first=True)\n",
        "\n",
        "features['target'] = (features['daily_pnl'] > 0).astype(int)\n",
        "\n",
        "features.dropna(inplace=True)\n",
        "\n",
        "features.to_csv(\"output/features.csv\", index=False)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 12. TRAIN MODEL (TIME SPLIT)\n",
        "# =============================\n",
        "\n",
        "print(\"\\nTraining predictive model...\")\n",
        "\n",
        "features = features.sort_values('date')\n",
        "\n",
        "split_index = int(len(features)*0.8)\n",
        "\n",
        "train = features.iloc[:split_index]\n",
        "test = features.iloc[split_index:]\n",
        "\n",
        "X_train = train.drop(columns=['account','date','daily_pnl','target'])\n",
        "y_train = train['target']\n",
        "\n",
        "X_test = test.drop(columns=['account','date','daily_pnl','target'])\n",
        "y_test = test['target']\n",
        "\n",
        "\n",
        "model = GradientBoostingClassifier(\n",
        "\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5\n",
        "\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "# Save model metrics\n",
        "with open(\"output/model_metrics.txt\",\"w\") as f:\n",
        "\n",
        "    f.write(\"Model: GradientBoostingClassifier\\n\")\n",
        "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
        "    f.write(f\"Training Samples: {len(X_train)}\\n\")\n",
        "    f.write(f\"Test Samples: {len(X_test)}\\n\")\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 13. CREATE CHARTS\n",
        "# =============================\n",
        "\n",
        "print(\"\\nGenerating charts...\")\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(x='sentiment', y='closedPnL', data=merged_analysis)\n",
        "plt.title(\"PnL Distribution vs Market Sentiment\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.savefig(\"output/charts/pnl_vs_sentiment.png\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='sentiment', y='size_usd', data=merged_analysis)\n",
        "plt.title(\"Trade Size vs Sentiment\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.savefig(\"output/charts/trade_size_vs_sentiment.png\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "freq_chart = pd.merge(trade_frequency, sentiment[['date','sentiment']], on='date')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='sentiment', y='num_trades', data=freq_chart)\n",
        "plt.title(\"Trade Frequency vs Sentiment\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.savefig(\"output/charts/trade_frequency_vs_sentiment.png\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 14. SUMMARY FILE\n",
        "# =============================\n",
        "\n",
        "with open(\"output/summary.txt\",\"w\") as f:\n",
        "\n",
        "    f.write(\"Trader Sentiment Analysis Summary\\n\\n\")\n",
        "\n",
        "    f.write(\"Model Accuracy:\\n\")\n",
        "    f.write(str(round(accuracy,4))+\"\\n\\n\")\n",
        "\n",
        "    f.write(\"Key Insights:\\n\")\n",
        "    f.write(\"- Trader performance varies across sentiment regimes\\n\")\n",
        "    f.write(\"- Trade size and frequency change based on sentiment\\n\")\n",
        "    f.write(\"- Historical trader performance predicts future profitability\\n\\n\")\n",
        "\n",
        "    f.write(\"Strategy Recommendations:\\n\")\n",
        "    f.write(\"- Reduce leverage during Fear sentiment\\n\")\n",
        "    f.write(\"- Increase trend-following during Greed sentiment\\n\")\n",
        "    f.write(\"- Follow consistently profitable traders\\n\")\n",
        "\n",
        "\n",
        "# =============================\n",
        "# COMPLETE\n",
        "# =============================\n",
        "\n",
        "print(\"\\n===================================\")\n",
        "print(\"ANALYSIS COMPLETE\")\n",
        "print(\"===================================\")\n",
        "\n",
        "print(f\"Final Accuracy: {accuracy:.4f}\")\n",
        "print(\"All files saved in output folder\")\n"
      ]
    }
  ]
}